{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'yelp_academic_dataset_business.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-10f64b85f2e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yelp_academic_dataset_business.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'yelp_academic_dataset_business.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as sk_data\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import MDS\n",
    "from matplotlib import pyplot\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from collections import OrderedDict\n",
    "from scipy.cluster.hierarchy import fcluster,dendrogram, linkage, cophenet\n",
    "from sklearn import mixture\n",
    "from scipy.spatial.distance import pdist\n",
    "%matplotlib inline\n",
    "\n",
    "def extract(obj):\n",
    "    ob = json.loads(obj)\n",
    "    for key, value in list(ob.items()):\n",
    "        if(key == 'categories'):\n",
    "            if ('Restaurants' not in value):\n",
    "                del ob[key]\n",
    "            else:\n",
    "                ob[key] = ','.join(value)    \n",
    "    return ob\n",
    "\n",
    "\n",
    "def process(data):\n",
    "    return \" \".join([SnowballStemmer('english').stem(word) for word in data])\n",
    "\n",
    "def convert(j):\n",
    "    for i in t15:\n",
    "        if(i == j):\n",
    "            return(t15.index(i)+1)\n",
    "\n",
    "def appending(j):\n",
    "    if j in t15:\n",
    "        c.append(j)\n",
    "        \n",
    "def evaluate_clusters(final_df,max_clusters):\n",
    "    error = np.zeros(max_clusters+1)\n",
    "    error[0] = 0;\n",
    "    for k in range(1,max_clusters+1):\n",
    "        kmeans = KMeans(init='k-means++', n_clusters=k, n_init=10)\n",
    "        kmeans.fit_predict(final_df)\n",
    "        error[k] = kmeans.inertia_\n",
    "    plt.figure(1)\n",
    "    plt.plot(range(1,len(error)),error[1:])\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Error')\n",
    "        \n",
    "#Read CSV instead of JSON\n",
    "df = pd.read_csv('yelp_toronto_min_test.csv')\n",
    "\n",
    "#Filtering for JSON that we need to do in mysql\n",
    "'''\n",
    "final_df = df[['latitude','longitude','city','categories']]\n",
    "final_df = final_df.loc[final_df['city'] == 'Las Vegas']\n",
    "final_df = final_df[['latitude','longitude','categories']]\n",
    "final_df = final_df.dropna(subset=['categories'])\n",
    "final_df[['latitude','longitude']] = (final_df[['latitude','longitude']].sub(final_df[['latitude','longitude']].mean())).divide(final_df[['latitude','longitude']].std())\n",
    "top15_df = final_df.copy()\n",
    "cat_list = final_df['categories'].tolist()\n",
    "x = []\n",
    "for i in cat_list:\n",
    "     x += [i.split(',')]\n",
    "\n",
    "        \n",
    "count={}\n",
    "for i in x:\n",
    "    for j in i:\n",
    "        if j not in count:\n",
    "            count[j]=1\n",
    "        else:\n",
    "            count[j] = count[j] +1\n",
    "top15_names=[]\n",
    "od = OrderedDict(sorted(count.items(), key=lambda kv:kv[1], reverse=True))    \n",
    "t15 = list(od)[1:16] # Eliminating Restaurants\n",
    "top15_names = t15\n",
    "t15_counts = list(od.values())[1:16]\n",
    "trimmed_list = []\n",
    "unwanted = []\n",
    "c =[]\n",
    "for i in final_df['categories']:\n",
    "    row = i.split(',')\n",
    "    c += [[convert(j) for j in row if j in t15]]\n",
    "    #c += [[ j for j in row if j in t15]]\n",
    "    \n",
    "    #trimmed_list.append(row)\n",
    "#print(c)\n",
    "top15_df['categories'] = c\n",
    "top15_df = top15_df.reset_index(drop = True)\n",
    "a = np.zeros(shape=(len(top15_df['categories']),15))\n",
    "i=0\n",
    "for j in c:\n",
    "    for k in j:\n",
    "        a[i,(k-1)] = 1\n",
    "    i+=1\n",
    "t15= pd.DataFrame.from_records(a)\n",
    "t15[['latitude','longitude']] = top15_df[['latitude','longitude']]\n",
    "evaluate_clusters(t15,10) #evaluates error versus number of clusters\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#K-means \n",
    "kmeans = KMeans(init='k-means++', n_clusters=5, n_init=100) \n",
    "km = kmeans.fit_predict(t15)\n",
    "centroids = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_\n",
    "\n",
    "\n",
    "def labels(cluster):\n",
    "    label_count ={}\n",
    "    for i in cluster[0]:\n",
    "        for j in top15_df['categories'][i]:\n",
    "            if j not in label_count:\n",
    "                label_count[j] = 1\n",
    "            else:\n",
    "                label_count[j] +=1\n",
    "    ord_dict = OrderedDict(sorted(label_count.items(), key=lambda kv:kv[1], reverse=True))\n",
    "    return ord_dict\n",
    "\n",
    "def cluster_label(lc,t15_counts):\n",
    "    maxi = 0\n",
    "    for key,value in lc.items():\n",
    "        temp = value/t15_counts[key-1]\n",
    "        if(temp>maxi):\n",
    "            maxi = temp\n",
    "            index = key-1\n",
    "    return top15_names[index]\n",
    "\n",
    "all_labels = []\n",
    "km_0 = np.where(km==0)\n",
    "lc = labels(km_0)\n",
    "all_labels.append(cluster_label(lc, t15_counts))\n",
    "\n",
    "km_1 = np.where(km==1)\n",
    "lc = labels(km_1)\n",
    "all_labels.append(cluster_label(lc, t15_counts))\n",
    "\n",
    "km_2 = np.where(km==2)\n",
    "lc = labels(km_2)\n",
    "all_labels.append(cluster_label(lc, t15_counts))\n",
    "\n",
    "km_3 = np.where(km==3)\n",
    "lc = labels(km_3)\n",
    "all_labels.append(cluster_label(lc, t15_counts))\n",
    "\n",
    "km_4 = np.where(km==4)\n",
    "lc = labels(km_4)\n",
    "all_labels.append(cluster_label(lc, t15_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
