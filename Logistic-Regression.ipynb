{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations ::  500\n",
      "   review_count  yelping_since_year  fans  is_elite\n",
      "0           245                2007    15         1\n",
      "1           245                2007    15         1\n",
      "2           245                2007    15         1\n",
      "3           245                2007    15         1\n",
      "4             2                2016     0         0\n",
      "Data set headers :: ['review_count', 'yelping_since_year', 'fans', 'is_elite']\n",
      "train_x size ::  (350, 3)\n",
      "train_y size ::  (350,)\n",
      "test_x size ::  (150, 3)\n",
      "test_y size ::  (150,)\n",
      "review_count_target_frequencies ::  {1: {0: 71, 1: 0}, 2: {0: 56, 1: 0}, 3: {0: 43, 1: 0}, 4: {0: 29, 1: 0}, 5: {0: 20, 1: 0}, 6: {0: 12, 1: 0}, 7: {0: 16, 1: 0}, 8: {0: 13, 1: 0}, 9: {0: 8, 1: 0}, 10: {0: 7, 1: 0}, 11: {0: 10, 1: 0}, 12: {0: 10, 1: 0}, 13: {0: 9, 1: 0}, 14: {0: 5, 1: 0}, 15: {0: 8, 1: 0}, 16: {0: 2, 1: 0}, 17: {0: 8, 1: 0}, 18: {0: 4, 1: 0}, 19: {0: 6, 1: 0}, 20: {0: 5, 1: 0}, 21: {0: 2, 1: 0}, 22: {0: 3, 1: 0}, 23: {0: 6, 1: 0}, 25: {0: 3, 1: 0}, 26: {0: 3, 1: 0}, 27: {0: 1, 1: 0}, 28: {0: 3, 1: 0}, 29: {0: 1, 1: 0}, 30: {0: 2, 1: 0}, 31: {0: 1, 1: 0}, 32: {0: 2, 1: 0}, 33: {0: 2, 1: 0}, 34: {0: 2, 1: 0}, 35: {0: 2, 1: 0}, 37: {0: 2, 1: 0}, 38: {0: 1, 1: 1}, 39: {0: 0, 1: 2}, 40: {0: 1, 1: 0}, 43: {0: 2, 1: 0}, 45: {0: 1, 1: 0}, 48: {0: 1, 1: 0}, 50: {0: 0, 1: 1}, 51: {0: 1, 1: 0}, 53: {0: 1, 1: 0}, 54: {0: 2, 1: 0}, 55: {0: 1, 1: 0}, 56: {0: 1, 1: 0}, 57: {0: 2, 1: 0}, 58: {0: 1, 1: 0}, 60: {0: 1, 1: 0}, 63: {0: 1, 1: 2}, 68: {0: 1, 1: 0}, 70: {0: 1, 1: 3}, 75: {0: 1, 1: 0}, 92: {0: 0, 1: 3}, 98: {0: 1, 1: 0}, 100: {0: 1, 1: 0}, 102: {0: 1, 1: 0}, 105: {0: 1, 1: 0}, 108: {0: 0, 1: 1}, 111: {0: 0, 1: 1}, 132: {0: 0, 1: 3}, 134: {0: 1, 1: 0}, 138: {0: 0, 1: 4}, 142: {0: 0, 1: 2}, 145: {0: 0, 1: 3}, 148: {0: 0, 1: 1}, 149: {0: 0, 1: 3}, 163: {0: 0, 1: 2}, 166: {0: 0, 1: 3}, 175: {0: 0, 1: 4}, 188: {0: 1, 1: 0}, 195: {0: 0, 1: 2}, 211: {0: 0, 1: 5}, 213: {0: 0, 1: 6}, 215: {0: 0, 1: 1}, 230: {0: 0, 1: 6}, 239: {0: 0, 1: 5}, 245: {0: 0, 1: 4}, 250: {0: 0, 1: 3}, 272: {0: 0, 1: 6}, 287: {0: 0, 1: 3}, 302: {0: 0, 1: 3}, 316: {0: 0, 1: 6}, 330: {0: 1, 1: 0}, 363: {0: 0, 1: 7}}\n",
      "Train Accuracy ::  0.965714285714\n",
      "Test Accuracy ::  0.966666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    " \n",
    "# import plotly.plotly as py\n",
    "# from plotly.graph_objs import *\n",
    "py.sign_in('ECE356-Lab4', 'pSqnDclLrzr62FAJuLHL')\n",
    " \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    " \n",
    " \n",
    "# Files\n",
    "DATA_SET_PATH = \"yelp_elite_user_min_test.csv\"\n",
    " \n",
    " \n",
    "def dataset_headers(dataset):\n",
    "    \"\"\"\n",
    "    To get the dataset header names\n",
    "    :param dataset: loaded dataset into pandas DataFrame\n",
    "    :return: list of header names\n",
    "    \"\"\"\n",
    "    return list(dataset.columns.values)\n",
    " \n",
    " \n",
    "def unique_observations(dataset, header, method=1):\n",
    "    \"\"\"\n",
    "    To get unique observations in the loaded pandas DataFrame column\n",
    "    :param dataset:\n",
    "    :param header:\n",
    "    :param method: Method to perform the unique (default method=1 for pandas and method=0 for numpy )\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if method == 0:\n",
    "            # With Numpy\n",
    "            observations = np.unique(dataset[[header]])\n",
    "        elif method == 1:\n",
    "            # With Pandas\n",
    "            observations = pd.unique(dataset[header].values.ravel())\n",
    "        else:\n",
    "            observations = None\n",
    "            print \"Wrong method type, Use 1 for pandas and 0 for numpy\"\n",
    "    except Exception as e:\n",
    "        observations = None\n",
    "        print \"Error: {error_msg} /n Please check the inputs once..!\".format(error_msg=e.message)\n",
    "    return observations\n",
    " \n",
    " \n",
    "def feature_target_frequency_relation(dataset, f_t_headers):\n",
    " \n",
    "    \"\"\"\n",
    "    To get the frequency relation between targets and the unique feature observations\n",
    "    :param dataset:\n",
    "    :param f_t_headers: feature and target header\n",
    "    :return: feature unique observations dictionary of frequency count dictionary\n",
    "    \"\"\"\n",
    " \n",
    "    feature_unique_observations = unique_observations(dataset, f_t_headers[0])\n",
    "    unique_targets = unique_observations(dataset, f_t_headers[1])\n",
    " \n",
    "    frequencies = {}\n",
    "    for feature in feature_unique_observations:\n",
    "        frequencies[feature] = {unique_targets[0]: len(\n",
    "            dataset[(dataset[f_t_headers[0]] == feature) & (dataset[f_t_headers[1]] == unique_targets[0])]),\n",
    "            unique_targets[1]: len(\n",
    "                dataset[(dataset[f_t_headers[0]] == feature) & (dataset[f_t_headers[1]] == unique_targets[1])])}\n",
    "    return frequencies\n",
    " \n",
    " \n",
    "def feature_target_histogram(feature_target_frequencies, feature_header):\n",
    "    \"\"\"\n",
    " \n",
    "    :param feature_target_frequencies:\n",
    "    :param feature_header:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    keys = feature_target_frequencies.keys()\n",
    "    y0 = [feature_target_frequencies[key][0] for key in keys]\n",
    "    y1 = [feature_target_frequencies[key][1] for key in keys]\n",
    " \n",
    "    trace1 = go.Bar(\n",
    "        x=keys,\n",
    "        y=y0,\n",
    "        name='Not an Elite User'\n",
    "    )\n",
    "    trace2 = go.Bar(\n",
    "        x=keys,\n",
    "        y=y1,\n",
    "        name='Elite User'\n",
    "    )\n",
    "    data = [trace1, trace2]\n",
    "    layout = go.Layout(\n",
    "        barmode='group',\n",
    "        title='Feature :: ' + feature_header + ' Elite User or Not Frequency',\n",
    "        xaxis=dict(title=\"Feature :: \" + feature_header + \" classes\"),\n",
    "        yaxis=dict(title=\"Elite User or Not Frequency\")\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    # plot_url = py.plot(fig, filename=feature_header + ' - Target - Histogram')\n",
    "    py.image.save_as(fig, filename=feature_header + '_Target_Histogram.png')\n",
    " \n",
    " \n",
    "def train_logistic_regression(train_x, train_y):\n",
    "    \"\"\"\n",
    "    Training logistic regression model with train dataset features(train_x) and target(train_y)\n",
    "    :param train_x:\n",
    "    :param train_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    " \n",
    "    logistic_regression_model = LogisticRegression()\n",
    "    logistic_regression_model.fit(train_x, train_y)\n",
    "    return logistic_regression_model\n",
    " \n",
    " \n",
    "def model_accuracy(trained_model, features, targets):\n",
    "    \"\"\"\n",
    "    Get the accuracy score of the model\n",
    "    :param trained_model:\n",
    "    :param features:\n",
    "    :param targets:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    accuracy_score = trained_model.score(features, targets)\n",
    "    return accuracy_score\n",
    " \n",
    " \n",
    "def main():\n",
    "    \"\"\"\n",
    "    Logistic Regression classifier main\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Load the data set for training and testing the logistic regression classifier\n",
    "    dataset = pd.read_csv(DATA_SET_PATH)\n",
    "    print \"Number of Observations :: \", len(dataset)\n",
    " \n",
    "    # Get the first observation\n",
    "    print dataset.head()\n",
    " \n",
    "    headers = dataset_headers(dataset)\n",
    "    print \"Data set headers :: {headers}\".format(headers=headers)\n",
    " \n",
    "    training_features = ['review_count', 'yelping_since_year', 'fans']\n",
    "    target = 'is_elite'\n",
    " \n",
    "    # Train , Test data split\n",
    "    train_x, test_x, train_y, test_y = train_test_split(dataset[training_features], dataset[target], train_size=0.7)\n",
    "    print \"train_x size :: \", train_x.shape\n",
    "    print \"train_y size :: \", train_y.shape\n",
    " \n",
    "    print \"test_x size :: \", test_x.shape\n",
    "    print \"test_y size :: \", test_y.shape\n",
    " \n",
    "    print \"review_count_target_frequencies :: \", feature_target_frequency_relation(dataset, [training_features[0], target])\n",
    " \n",
    "    for feature in training_features:\n",
    "        feature_target_frequencies = feature_target_frequency_relation(dataset, [feature, target])\n",
    "        feature_target_histogram(feature_target_frequencies, feature)\n",
    " \n",
    "    # Training Logistic regression model\n",
    "    trained_logistic_regression_model = train_logistic_regression(train_x, train_y)\n",
    "    \n",
    "    train_accuracy = model_accuracy(trained_logistic_regression_model, train_x, train_y)\n",
    " \n",
    "    # Testing the logistic regression model\n",
    "    test_accuracy = model_accuracy(trained_logistic_regression_model, test_x, test_y)\n",
    " \n",
    "    print \"Train Accuracy :: \", train_accuracy\n",
    "    print \"Test Accuracy :: \", test_accuracy\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
